\chapter{Experiment Design and Results}
\paragraph{Overview} This chapter describes the experiment that we conducted based on the system design showed in chapter~\ref{sec} and our final results, consisting in the trained model and its evaluation. In particular, in section~\ref{sec:nn} we present the selected architecture among the different possibilities in recent literature. Section~\ref{sec:input_metrics_sample} describes all the necessary details about the input selection, the chosen evaluation metrics and how results are produced. Section~\ref{sec:results} presents the resulting model, the metrics associated to it and some examples of generated levels. 
\section{Neural Network Architecture and Training Algorithm}
\label{sec:nn}
\subsection{Network Architecture and Hyper-parameters}
\label{sec:networkarch}

\subsubsection{Chosen Architecture}
\paragraph{Overview} Among the proposed variants of \gslpl{gan} that are proposed in the literature, we selected the Wesserstein GAN with Gradient Penalty \cite{wgangp} (WGAN-GP) from \citeauthor{wgangp}. This architecture is proposed as an enhanced version of the WGAN \cite{wgan}. In the WGAN architecture, the discriminator is more properly called "critic", as it is a network that is not trained to discriminate  true and generated samples but rather to evaluate them \citeauthor{wgangp}.%TODO: Inserisci pagina

\paragraph{Network Layers}

\subsubsection{Critic Loss and Generator Loss}
\paragraph{Overview}
\paragraph{Critic Loss}
We implement the Critic loss as in the \citetitle{wgangp} official implementation \cite{wgangp_imple}:
% TODO: Scrivi l'update rule della loss di wgangp



% Dai un'interpretazione alla loss e spiega il GP
\paragraph{Generator Loss}
The generator loss is defined as:

%TODO Interpretazione
\subsubsection{Motivation} %TODO: This
\label{sec:arch_advantages}
%TODO Parla dei vantaggi e soprattutto del problema della (validation) loss che non sempre è sinonimo di qualità dei samples, citando i paper.

% Considerando il modello utilizzato, https://openreview.net/forum?id=Sy1f0e-R- dimostra che è in realtà piuttosto difficile che una GAN riesca ad imparare esattamente i sample del training set, anche con un numero molto ridotto di elementi.

\subsubsection{Other details} %TODO: Techniques and "GAN Tricks" used

\subsubsection{Training Algorithm}
% Show the table with the steps at each iteration and motivate them


\section{Input selection, Metrics and Sample Method}
\label{sec:input_metrics_sample}
\subsection{Input data}
\label{sec:InputSelection}
 % TODO Inserire Constraints su tfrecords


\subsection{Evaluation metrics}
\label{sec:evaluation}
%TODO: Parla del fatto che di solito si usa inception score o simili. Cita anche il paper in cui proponevano modi alternativi che però dipendevano comunque da reti neurali e i risultati ottenuti non sono stati soddisfacenti. Poi proponi e spiega le metriche e parla del fatto che è comunque difficile trovare metriche sensate per comparare il tipo di dati su cui lavoriamo.
\paragraph{Overview} We define 
\subsubsection{Entropy Mean Absolute Error}
\subsubsection{Structural Similarity Mean Absolute Error}
\subsubsection{Encoding Error}
\subsubsection{Corner Error}
\paragraph{} This metric is inspired by the work of ...%TODO:Paper robotica
We define the Corner Error as
%TODO: Definizione


\subsection{Sampling the network}


\section{Results}
\label{sec:results}
\subsection{Resulting Model}
\label{sec:sampling}
% Alcune considerazioni su come viene campionata la rete 
% Eventuale sezione sull'interpolazione di livelli
\section{Generated Samples}
\section{In-Game Demonstration}
\section{Summary}
