\chapter{Results Evaluation and Conclusions}
\section{Results Evaluation}


\section{Conclusions}
\paragraph{} Although the model we designed is far for being perfect in solving the level generation problem for 2d non-linear environment such DOOM maps, we think it's still a good starting point for future improvements and could represent a viable alternative to classical Procedural Generation. In particular, most of the levels generated from the network have proved to be interesting to explore and play due to the presence of particular features typical of doom maps, such as narrow tunnels and large rooms. This suggest that one of the advantages of our method with respect to Procedural Generation is that in our case there is no need of an expert designer to embed it's knowledge in the generation process; still, this method allows the designer to focus on the selection of more high-level features as those we selected as network inputs. This generative method, which is commonly used to produce visually appealing images, proved to be applicable to a topological setting like ours, even if not without issues: While in creating a picture of a face, a small variation in colour intensity is quite unnoticeable and can be tolerated, in our domain even a pixel-sized difference in a level map could alter drastically the level topology itself, for example creating a new access between two areas. This issue is emphasized by the output noise which is quite common in samples generated by a GAN.

\paragraph{} When using this type of models, one of the most common concerns is that the network could overfit the training set, learning to reproduce the samples of the dataset. While we cannot prove it formally, we refer to the results of \citeauthor{empiricalevaluation} in \cite[Appendix~C]{empiricalevaluation}, which claim that overfitting the model we used in our work is difficult even for a small number of training samples, de facto demonstrating that the behaviour of GANs is different from that of classical deep neural networks used for classification. One result that intuitively supports this consideration is given by the fact that when we generated 1000 levels for each input feature we often obtained feature distributions with large variance, which makes improbable that the discriminator could have overfit the dataset levels.



\section{Future Work}
\paragraph{} In this section we first present the general open problems we encountered in our setting, then we propose some specific works that can be made to improve our system.
\subsection{Open Problems}
\subsubsection{Data Availability}
\paragraph{} The amount of data available is a problem that affects in general every deep learning setting. As discussed in earlier sections, the context of video-games is one of field in which data is less available and uniform. In our work we used a dataset of 1088 levels which have been augmented by rotation due to memory size constraints, but we envision that a larger amount of levels could make the network more accurate in generating levels. We propose a possible improvement for our system in section \ref{sec:data-augmentation}.
\subsubsection{Samples Evaluation}
\paragraph{} As we explained in section~\ref{sec:evaluation}, the problem of evaluating the samples generated by a GAN is still a recent field of research and still a general prevailing model have to be proposed. Moreover, the particular domain of our work makes even more difficult to apply commonly used methods to assess the quality. In section~\ref{sec:evaluation} we proposed a qualitative method for assessing the generated sample quality during the training process according to our data. While the method we applied succeeds in indicating that the network is actually learning the level structures, the metrics we proposed have the drawback that they need to be considered altogether but calculated on each map differently in order to benefit of their informational power.

\subsubsection{Loss of accuracy}
\paragraph{} The system we designed assumes that one pixel is equivalent to 32 Doom Map Units since it's the diameter of the smallest object in DOOM. While this ensures that objects cannot overlap on the image representation, it introduces an unavoidable loss of accuracy in object positioning. Moreover, using a single pixel for representing objects such as in "Thing Maps" makes the task of distinguish generated object from noise and artefacts more difficult. While we weren't able to detect artefacts in the structural maps such as the floormap, wallmap and heightmaps, the generated \glspl{thingsmap} often shows a placement of objects that is too regular, resembling the checker board artefacts we discussed in section~\ref{sec:artefacts-reduction}. We envision that an increase of dataset resolution, for example setting one pixel size to 16 MU instead of 32, would help in reducing this problem. 

\subsubsection{Improving Network Sampling}
\label{sec:sampling}
\paragraph{} Due to the high dimensionality of the feature space, sampling the resulting network using arbitrary feature values often results in low quality samples, for this reason we sample the network around points in the feature space for which the network have been trained. However, in real application it could be better to have the designer specify his own desired input features, such desired area, the balance between large halls and corridors, etc. We envision that this issue could be reduced using more training data and possibly using soft labels as proposed by \cite{improved_gan}, at the cost of some noise in the output.

\subsection{Possible Applications and future develops}
\subsubsection{Augmenting input data}
% Augmenting the dataset splitting levels by floor
\label{sec:data-augmentation}
\paragraph{} In our work we only used levels having a single "floor", or connected figure, in order to avoid letting the network learn unnecessary patterns like the position or rotation of the various floors that compose the level when they actually are irrelevant from a playability point of view. One method for increasing the number of training samples is re-generating the dataset considering each floor as a separated level and calculating the features on a floor basis. An additional method for using a larger part of the data we collected is to simply increase the input/output sample size, although this require more computational capabilities. 

\subsubsection{Better samples to WAD conversion}
\paragraph{} In our work we focused on the generation process, while we did some work for providing a simple method for playing the generated levels in DOOM. However, this method is still not perfect: only preliminary work have been done on applying the height differences in levels, and no visual improvements such as automatic texture selection have been implemented yet. Moreover, work have still to be done for decorating the level with doors, elevators and switches. 

 \subsubsection{Sample interpolation and Style Transfer}
\paragraph{} An interesting practice for generating diverse samples and assessing the generalization capabilities of the network is the interpolation of samples in the feature space \cite{slerp}. We provided a method for sampling interpolated batches of levels by providing a start and end point in feature space, while keeping the noise vector fixed. If we consider adding levels from other games to the dataset by converting them to the same domain we used, this technique can be easily used to "merge" levels from different game and study what different features they exhibit.

\subsubsection{Tweaking the model}
% Alternative models
\paragraph{} For increasing the model capabilities a lot of work can still be done. One first attempt could be changing the network hyperparameters in order to find a setting that allows the network to learn a better representation. This work has been attempted while searching a good architecture and we didn't find any improvements over the default settings, although we cannot prove we are using optimal values.

\subsubsection{Different architectures}
% Hybrid method based on autoencoders
\paragraph{} Due to the constant research in generative models, there is an always increasing number of different new models to try and experiment in order to improve the generation of samples. In our work we limited our search only to the mostly used pure-GAN models which didn't require too much computational power, but a large number of models are available.
For example, one method that showed good results on faces generation that mixes GANs and Autoencoders is the BEGAN model proposed by \citeauthor{gan:BEGAN} in \cite{gan:BEGAN}. Another approach could be the one for high-resolution images such as in \textit{\citetitle{gan:high-res}} \cite{gan:high-res}, showing interesting improvements in visual quality by growing the generator and the discriminator progressively.

\subsubsection{Possible Applications}
The most obvious application of our work would be the case of off-line video-game level generation. In particular our work finds application whenever it is needed to obtain 3d maps which doesn't overlap on the height axis. Since the only requirement for the levels to work with our framework is the one we just stated, it is possible to extend this system to other environments and domains by just changing the feature extraction modules. In other words, the system is independent of the technology of the particular game we used for training, and it can be used virtually in any type of 3d game or simulation in which the user can move in two dimensions, eventually with changes of floor height. Possible applications in another fields could be the generation of environments for training or testing the behaviour of AI agents, and the use of the discriminator network for classification tasks by adding a last layer and fine tuning the network. However, due to the set-up requirements currently needed for running the project, a most probable application that we envision of our work is as a starting point for the development of more complex systems or more advanced studies on Procedural Content Generation via Machine Learning applied to this type of environments.

