\chapter{Conclusions and Future Work}
\label{ch:conclusions}
\paragraph{} In this chapter we make general conclusions about our work, while providing a set of open problems and the works that still have to be made. Section~\ref{sec:conclusions} reports our final conclusions, while section \ref{sec:futurework} highlights the possible future develops for enhancing our results.


\section{Conclusions}
\label{sec:conclusions}

\paragraph{} In chapter \ref{sec:results} we showed how the addition of features to the network inputs increases the quality of generated samples and leads to better learning of many features, while also providing a method to influence the network output during the sampling process. One of the most common concerns is that the network could overfit the training set, learning to reproduce samples from the dataset. While we cannot prove it formally, we refer to the results of \citeauthor{empiricalevaluation} in \cite[Appendix~C]{empiricalevaluation}, which claim that overfit is difficult to occur in the type of model we used, even for a small number of training samples, de facto demonstrating that the behaviour of GANs is different from that of classical deep neural networks used for classification.


\paragraph{} Although the model we designed is far for being perfect in solving the level generation problem for 2d non-linear environments such DOOM maps, we think it's still a good starting point for future improvements and could represent a viable alternative to classical Procedural Generation. In particular, most levels generated from the networks have proved to be interesting to explore and play due to the presence of particular features typical of doom maps, such as narrow tunnels and large rooms. This suggests that one of the advantages of our method with respect to Procedural Generation is that in our case there is no need of an expert designer to embed their knowledge in the generation process; still, this method allows the designer to focus on the selection of more high-level features as those we selected as network inputs. This generative method, which is commonly used to produce visually appealing images, proved to be applicable to a topological setting like ours, even if not without issues: While in creating a picture of a face, a small variation in colour intensity is quite unnoticeable and can be tolerated, in our domain even a pixel-sized difference in a level map could alter drastically the level topology itself, for example creating a new access between two areas. This issue is emphasized by the output noise which is quite common in samples generated by a GAN.

\clearpage

\section{Future Work}
\label{sec:futurework}
\paragraph{} In this section we first present the open problems we encountered in our setting, then we propose some specific works that can be made to improve our system.
\subsection{Open Problems}
\subsubsection{Data Availability}
\paragraph{} The amount of data available is a problem that affects in general every deep learning setting. As discussed in earlier chapters, the context of video-games is one of the fields in which data is less available and uniform. In our work we used a dataset of 1088 levels which have been augmented by rotation due to memory size constraints, but we envision that a larger amount of levels could make the network more accurate in generating levels. We propose a possible improvement for our system in section \ref{sec:data-augmentation}.
\subsubsection{Samples Evaluation}
\paragraph{} As we explained in section~\ref{sec:evaluation}, the problem of evaluating the samples generated by a GAN is still a recent field of research and a general prevailing model still have to be proposed. Moreover, the particular domain of our work makes even more difficult to apply the commonly used methods to assess sample quality. In section~\ref{sec:evaluation} we proposed a qualitative method for assessing the generated sample quality during the training process that works with our data. While the method we applied succeeds in indicating that the network is actually learning the level structures, the metrics we proposed have the drawback that they need to be calculated on each map differently in order to benefit of their informational power, while considered altogether for assessing the general sample quality. 

\subsubsection{Loss of accuracy}
\paragraph{} The system we designed assumes that one pixel is equivalent to 32 Doom Map Units since it's the diameter of the smallest object in DOOM. While this ensures that objects cannot overlap on the image representation, it introduces an unavoidable loss of accuracy in object positioning. Moreover, using a single pixel for representing objects such as in "Thing Maps" makes the task of distinguish generated object from noise and artefacts more difficult. While we weren't able to detect checker board artefacts in the structural maps such as the floormap, wallmap and heightmaps, the generated \glspl{thingsmap} often show an object placement that is too regular, resembling the issue discussed in section~\ref{sec:artefacts-reduction}. We envision that an increase of the dataset resolution, for example setting one pixel size to 16 MU instead of 32, would help in reducing this problem. This comes at the cost of choosing between an high resolution in representing the maps and an higher resolution in network input/output, which also allows to use more levels from the full dataset.

\subsubsection{Improving Network Sampling}
\label{sec:sampling}
\paragraph{} Due to the high dimensionality of the feature space, sampling the conditional network using arbitrary feature values often resulted in low quality samples, for this reason we sample the network around points in the feature space for which the network have been trained. However, in real applications it could be better to have the designer specify his own desired input features, such the area, the balance between large halls and corridors, etc. We envision that this issue could be reduced using more training data and possibly using soft labels as proposed by \cite{improved_gan}, at the cost of a possible increase of noise in the output. An alternative design could be the implementation of the "Content Sampling" introduced in section \ref{sec:usecase_sampling}.

\subsection{Possible Applications and future develops}
\subsubsection{Augmenting input data}
\label{sec:data-augmentation}
\paragraph{} In our work we only used levels having a single "floor", or connected figure, in order to prevent the network for learning unnecessary patterns like the position or rotation of the various floors that compose the level when they actually are irrelevant from a gameplay point of view. One method for increasing the number of training samples is re-generating the dataset considering each floor as a separated level and calculating the features on a floor basis. An additional method for using a larger part of the data we collected is to simply increase the input/output sample size, although this require more computational capabilities. 

\subsubsection{Improving samples to WAD conversion}
\paragraph{} In our work we focused on the generation process, while we also provided a simple method for playing the generated levels in DOOM. However, this method is still not perfect: only preliminary work have been done on applying the height differences in levels, and no visual improvements such as automatic texture selection have been implemented yet. Moreover, work have still to be done for decorating the level with doors, elevators and switches. 

 \subsubsection{Sample interpolation and Style Transfer}
\paragraph{} An interesting practice for generating diverse samples and assessing the generalization capabilities of the network is the interpolation of samples in the feature space \cite{slerp}. We provided a method for sampling interpolated batches of levels by providing a start and end point in feature space, while keeping the noise vector fixed. If we consider adding levels from other games to the dataset by converting them to the same domain we used, this technique can be easily used for interpolating levels from different games and study what different features they exhibit.

\subsubsection{Tweaking the model}
% Alternative models
\paragraph{} For increasing the model capabilities a lot of work can still be done. One first attempt could be tweaking the network hyperparameters in order to find a setting that allows the network to learn a better representation. Our attempts didn't find any improvements over the default settings, although we cannot prove we are using optimal values.

\subsubsection{Different architectures}
% Hybrid method based on autoencoders
\paragraph{} Due to the constant research in generative models, there is an always increasing number of different new models to try and experiment in order to improve the generation of samples. In our work we limited our search only to the mostly used pure-GAN models which could easily run on our machines, but a large number of models can still be applied.
For example, one method showing good results on faces generation that mixes GANs and Autoencoders is the BEGAN model proposed by \citeauthor{gan:BEGAN} in \cite{gan:BEGAN}. Another approach could be using high-resolution models such as in \textit{\citetitle{gan:high-res}} \cite{gan:high-res}, showing interesting improvements in visual quality by growing the generator and the discriminator progressively.

\subsubsection{Possible Applications}
The most obvious application of our work would be the case of off-line video-game level generation. In particular our work finds application whenever it is needed to obtain 3d maps which doesn't overlap on the height axis. Since this is the only particular requirement for levels to work with our framework, it is possible to extend this system to other environments and domains by just changing the feature extraction modules. In other words, the system is independent of the technology of the particular game we used for training, and it could be virtually used in any type of 3d game or simulation in which the user can move in two dimensions, eventually with changes of floor height. Possible applications in another fields could be the generation of environments for training or testing the behaviour of AI agents, and the use of the trained discriminator network for classification tasks by adding a last layer and fine tuning the resulting network. However, due to the set-up requirements currently needed for running the project, a most probable application that we envision of our work is as a starting point for the development of more complex systems or more advanced studies on Procedural Content Generation via Machine Learning applied to this type of environments.

