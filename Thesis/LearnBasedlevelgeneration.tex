\chapter{Towards learn-based level generation}
%TODO: Rescrivi questo. Lo scopo del capitolo Ã¨ di dare un overview delle tecniche che abbiamo utilizzato nel nostro lavoro in modo che sia meglio comprensibile il lavoro che abbiamo fatto. Inoltre 
\paragraph{} This chapter further describes the setting of our work and gives the reader some overview of the tools and techniques we used in our work. Section~\ref{sec:gantheory} first provides the theoretical background necessary to better understand the setting in which our work take place. Then, section~\ref{sec:doominfo} describes and motivates the choice of the game we work with. 
%TODO: Bisogna anche sottolineare la congiunzione tra ML e PGC, che ha originato questa tesi
\section{Theoretical Background}
\label{sec:gantheory}
\subsection{Overview}
\paragraph{} As the main model for generating levels we selected the Generative Adversarial Networks. This model showed good results in many applications and it's increasingly more adopted and studied in the research community. Due to this, a large variety of different architectures and variants are designed in order to improve the original model. In this section we present an introduction to the \gls{gan} model and the main variant we considered for selecting the final model. 

\subsubsection{GAN}
\label{sec:introgan}
\paragraph{} Generative Adversarial Network, proposed by \citeauthor{gan} in \citetitle{gan} (\citeyear{gan}) \cite{gan}, are a model that gained gained increasingly more interest in the latest years. The main idea of this kind of generative model is to use two neural networks which are posed in an adversarial setting that models a two-player Minimax Game \cite[p.~276]{minimax}. In particular, a generative network $G$ is trained to capture the data distribution while a discriminator network $D$ estimates the probability that each sample comes from the real data distribution rather than the one generated by $G$. 
Equation \ref{eq:ganloss} shows the losses for D and G in the original \gls{gan} architecture\cite{gan}:

\begin{equation}
\label{eq:ganloss}
%\tag{WGAN-GP Critic Loss}
\begin{split}
L_{D}^{(i)} \gets & \frac{1}{m} \sum_{i=1}^m \left[
\log D\left({x}^{(i)}\right)
+ \log \left(1-D\left(G\left({z}^{(i)}\right)\right)\right)
\right] \\
%\tag{WGAN-GP Generator Loss}
L_{G}^{(i)} \gets & \frac{1}{m} \sum_{i=1}^m
\log \left(1-D\left(G\left({z}^{(i)}\right)\right)\right)
\end{split}
\end{equation}

where ${z}^{(i)}$ is a batch of random noise samples and ${x}^{(i)}$ is a batch of true data samples. \\*
The two networks are trained alternately by \textit{Backpropagation}, in this way the generator network can learn to produce better samples by using the discriminator output as a sort of feedback. 

\subsection{Deep Convolutional GAN (DCGAN)}
Typically, training a Generative Neural Network is a difficult task. This is, among other reasons, due to the need of balancing the generator and the discriminator during the minimax optimization. In order to overcome these difficulties, \citeauthor{gan:dcgan} proposed the DCGAN model \cite{gan:dcgan} which offer some improvements over the standard \gls{gan} architecture. The main modifications introduced are the use of convolutional layers instead of fully connected and max-pooling, the use of batch normalization \cite{batchnorm} and ReLu activation functions \cite{relu}. DCGAN architecture became one of the main baselines to build projects involving \glspl{gan} and compare new architectures. In our work we used the DCGAN layer structure showed in figure \ref{fig:dcganlayers} as a starting point for our experiments, which differs from ours for the presence of the conditioning input, the stride and the input size. These details on our architecture will be explained in chapter~\ref{ch:experiment}.

\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=1\linewidth]{DCGAN_layers}
	\end{center}
	
	\captionsetup{width=1\linewidth}
	\caption[Layers  from DCGAN, \citeauthor{gan:dcgan}]{DCGAN generator layers from the work of \citeauthor{gan:dcgan} on the LSUN dataset \cite[p.4]{gan:dcgan}.}
	\label{fig:dcganlayers}
	\medskip
\end{figure}

\subsection{Wasserstein GAN}
\paragraph{} Despite of the improvements, \glspl{gan} are still affected by some problems: training stability is dependent on the network structure, the training loss does not converge and not reflecting the actual sample quality. The Wasserstein GAN architecture, introduced by \citeauthor{wgan} \cite{wgan}, aims to mitigate these problems. The authors build a new loss function, based on the fact that training a GAN can be interpreted as minimizing the \textit{Jensen-Shannon divergence}\cite{jsdivergence}. They also prove how the Wasserstein (or Earth-Mover) \cite[\S~3]{wgan} distance is more sensible in the considered setting. \\* The resulting loss function is an approximation to the Wasserstein distance:

\begin{equation}
\label{eq:wganloss}
\begin{split}
L_{Critic}^{(i)} \gets & \mathbb{E}(D(X_{Gen})) - \mathbb{E}(D(X_{True}))\\
L_{Gen}^{(i)} \gets & -D(X_{Gen}) 
\end{split}
\end{equation}

This approximation is derived from an alternative formulation of the Wasserstein distance, which requires to calculate a supremum over \textit{K-Lipschitz} functions. To force the network to only model K-Lipschitz functions the weights of the critic network are clamped, and no output functions are applied to the discriminator function, in this case called \textit{critic}.  

\subsection{Wasserstein GAN with Gradient Penalty}
\paragraph{} \citeauthor{wgangp} remark in \cite{wgangp} that the WGAN architecture suffers from some optimization problems related to the weight clipping. Their experiment shows that gradient often vanishes or explodes if the weight clipping is not tuned carefully, and that this technique also biases the network toward too simple functions. To overcome these problems, they propose an alternative way to enforce the \textit{Lipschitz constraint} by keeping the gradient at unitary size. This involves adding a penalty term to the critic loss to enforce the constraint only along straight lines between the real and the generated data distribution, which leads to good results and performances.

\begin{equation}
\label{eq:gp}
\begin{split}
\hat{X} & \gets \epsilon X_{True} + (1-\epsilon) X_{Gen} \\
G_p & \gets (\| \nabla_{\hat{X}}D(\hat{X}) \|_2 - 1 )^2
\end{split}
\end{equation}

Results obtained from \citeauthor{wgangp} on the LSUN dataset are shown in Figure \ref{fig:wgangp}.
%TODO: Cita questa immagine
\begin{figure}[h!]
	\begin{center}
		\includegraphics[width=1\linewidth]{wgangp_example}
	\end{center}
	
	\captionsetup{width=1\linewidth}
	\caption[Samples from WGAN-GP, \citeauthor{wgangp}]{Examples from the work of \citeauthor{wgangp} on the LSUN dataset using WGAN-GP. \cite[p.8]{wgangp}}
	\label{fig:wgangp}
	\medskip
\end{figure}

\subsubsection{Conditional GAN}
\paragraph{} In our work we apply a modification of the \gls{gan} model introduced by \citeauthor{conditionalgan} \cite{conditionalgan} to the WGAN-GP, which allows to condition the data generation to class labels. The motivation we chose this model is to allow with some extent the generation process, instead of generating random samples; this also allows the network learn useful information encoded in the feature vector and exploit it to generate better results. The logical structure of the adopted generative model is summarized in section \ref{sec:modelstructure}.


\subsubsection{Additional Architectures}
\paragraph{} Due to the novelty of this model, many researches have been conducted to improve the quality performances of \glspl{gan}, leading to a variety of proposed new architectures. They can be classified as modifications to the underlying neural network architectures or even to the conceptual setting of the model itself, by means of changes to the loss function or the training algorithm. Other, less formal but still effective adjustment to the proposed models are the so called "tricks" in machine learning discussion communities, which adoption is often suggested in order to improve the difficult training of the network. The final architecture adopted is described in section \ref{sec:networkarch}.


\section{Game of choice: DOOM}
\label{sec:doominfo}
\subsection{Description}
\subsection{Motivation}
% Parla del game engine, dei livelli piatti (limitazione/vantaggio), dataset disponibile, grande community ancora attiva, ben documentato



\section{Summary}
