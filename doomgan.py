import numpy as np
import os
from multiprocessing.dummy import Pool as ThreadPool
from multiprocessing import cpu_count
import time

class DoomSampler():

    def __init__(self, current_dir='.', tf_session_configproto=None):
        import DoomLevelsGAN.DoomGAN as Gan
        import WAD_Parser.WADFeatureExtractor as fe

        self.gan = Gan.init(current_dir=current_dir, configproto=tf_session_configproto)
        self.session = self.gan.session
        self.extractor = fe.WADFeatureExtractor()
        self.last_generated_samples = None
        print("Initializing DoomGAN...")
        self.gan.initialize_and_restore()
        print("INFO: Feature extraction will be made using {} threads".format(cpu_count()))
        print("DoomGAN is ready.")



    def get_features_of(self, input_noise, input_features, benchmark=False, thread_count=cpu_count()):
        """
        Gets the list of features computed from the samples generated by input_noise and input_features.
        :param input_noise: Generation noise. Must be an array of shape (batch_size [32], z_dim [100])
        :param input_features: Input features for the conditional network. Must be an array of shape (batch_size [32], n_input_features)
        :return: A dictionary containing feature names as key and the list of feature values (of length batch_size) as values
        """
        assert input_noise.shape == (self.gan.config.batch_size, self.gan.config.z_dim), \
            "Input Noise must have shape (batch_size, z_dim), which is ({},{})".format(
                self.gan.config.batch_size, self.gan.config.z_dim)
        if self.gan.use_features:
            assert input_features.shape == (self.gan.config.batch_size, len(self.gan.features)), \
                "Input Features must have shape (batch_size, n_features), which is ({},{})".format(self.gan.config.batch_size, len(self.gan.features))

        out_features = dict()


        # Associating map names to sample indices
        fm_idx = self.gan.maps.index("floormap")
        wm_idx = self.gan.maps.index("wallmap")
        tm_idx = self.gan.maps.index("thingsmap")


        time_gen_start = time.time() if benchmark else None
        self.last_generated_samples = self.gan.sample(mode='direct', y_batch=input_features, z_override=input_noise, postprocess=True).astype(np.uint8)
        print("Generation of {} samples took {} seconds".format(self.gan.config.batch_size, time.time()-time_gen_start)) if benchmark else None
        if thread_count > 1:
            # This function takes the list of samples that has to be processed for each single thread (len=2 if 32 samples and 16 threads)
            def extraction(sample_list):
                feature_list = list()
                for s in sample_list:
                    # This manages errors in feature computation due to degenerate levels
                    feature = None
                    try:
                        feature = self.extractor.extract_features_from_maps(s[:, ..., fm_idx], s[:, ..., wm_idx], s[:, ..., tm_idx])
                    except:
                        print("Cannot compute features for a requested map")
                    feature_list.append(feature)
                return feature_list

            time_feat_start = time.time() if benchmark else None
            pool = ThreadPool()
            temp_features = pool.map(extraction, np.array_split(self.last_generated_samples, thread_count, axis=0))
            pool.close()
            pool.join()
            print("Feature calculation of {} samples took {} seconds with {} threads".format(self.gan.config.batch_size,
                                                                    time.time() - time_feat_start, thread_count)) if benchmark else None
            # Now temp_features has dimensions (n_threads, samples_per_thread, n_features)
            # merging the first two dimensions to obtain (n_samples, n_features)
            temp_features = np.concatenate(temp_features, axis=0)
        else:
            temp_features = list()
            for s in self.last_generated_samples[:, ...]:
                # This manages errors in feature computation due to degenerate levels
                feature = None
                try:
                    feature = self.extractor.extract_features_from_maps(s[:, ..., fm_idx], s[:, ..., wm_idx], s[:, ..., tm_idx])
                except:
                    print("Cannot compute features for a requested map")
                temp_features.append(feature)
        # Converting list of dicts to dict of lists
        # Finding the representative dict from which to extract the columns
        repr = None
        for dic in temp_features:
            if dic is not None:
                repr = dic
        if repr is None:
            return None
        for feature in repr:
            out_features[feature] = []
            for sample_dict in temp_features:
                if sample_dict is not None:
                    out_features[feature].append(sample_dict[feature])
                else:
                    out_features[feature].append(None)
        return out_features

    def generate_random_levels(self, output_folder='./artifacts/generated_samples/'):
        os.makedirs(output_folder, exist_ok=True)
        if len(self.gan.features) > 0:
            self.gan.initialize_and_restore()
            self.gan.sample(mode='dataset', sample_from_dataset='validation', postprocess=True,
                            save='WAD', folder=output_folder)

def example():
    """
    Example of code returning features for 32 generated levels
    """
    sampler = DoomSampler()
    # Current architecture works on batches of 32 levels
    # Noise shape is (batch_size, 100)
    noise_shape = [32, 100]
    # Input Feature vector shape is (batch_size, 7) - Refer to DoomLevelsGAN/network_architecture.py
    feat_shape = [32, 7]

    # Generating random noise and input features as example
    noise = np.random.random(size=noise_shape)
    input_features = np.random.random(size=feat_shape)
    out_features = sampler.get_features_of(noise, input_features)

    # Retrieving samples
    levels = sampler.last_generated_samples

    # Printing feature values
    for f_name, f_list in out_features.items():
        print("Feature: {} \n {}".format(f_name, f_list))

def generate_some_levels():
    sampler = DoomSampler()
    sampler.generate_random_levels()


